{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5EoiGWmGjaz5BBdKcLyVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laussin86/Capstone-project/blob/main/Python_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scrapping data from zillow. \n",
        "- **Having issue getting the data with this code**\n",
        "\n",
        "  - bsobj = soup(html.content,'lxml')\n",
        "\n",
        "    bsobj\n",
        "- **Scrapping image issue**\n",
        "\n",
        "from selenium import webdriver\n",
        "\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "import requests\n",
        "\n",
        "import io\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "\n",
        "PATH = \"C:\\\\Users\\\\Tim\\\\Desktop\\\\Web Scraping Images\\\\chromedriver.exe\"\n",
        "\n",
        "wd = webdriver.Chrome(PATH)\n",
        "\n",
        "def get_images_from_google(wd, delay, max_images):\n",
        "\t\n",
        "  def scroll_down(wd):\n",
        "\t\t\n",
        "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\t\ttime.sleep(delay)\n",
        "\n",
        "\turl = \"https://www.zillow.com/san-francisco-ca/sold/\"\n",
        "\twd.get(url)\n",
        "\n",
        "\timage_urls = set()\n",
        "\tskips = 0\n",
        "\n",
        "\twhile len(image_urls) + skips < max_images:\n",
        "\t\tscroll_down(wd)\n",
        "\n",
        "\t\tthumbnails = wd.find_elements(By.CLASS_NAME, \"gjWytb\")\n",
        "\n",
        "\t\tfor img in thumbnails[len(image_urls) + skips:max_images]:\n",
        "\t\t\ttry:\n",
        "\t\t\t\timg.click()\n",
        "\t\t\t\ttime.sleep(delay)\n",
        "\t\t\texcept:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\timages = wd.find_elements(By.CLASS_NAME, \"n3VNCb\")\n",
        "\t\t\tfor image in images:\n",
        "\t\t\t\tif image.get_attribute('src') in image_urls:\n",
        "\t\t\t\t\tmax_images += 1\n",
        "\t\t\t\t\tskips += 1\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tif image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
        "\t\t\t\t\timage_urls.add(image.get_attribute('src'))\n",
        "\t\t\t\t\tprint(f\"Found {len(image_urls)}\")\n",
        "\n",
        "\treturn image_urls\n",
        "\n",
        "\n",
        "def download_image(download_path, url, file_name):\n",
        "\t\n",
        "  try:\n",
        "\t\t\n",
        "    image_content = requests.get(url).content\n",
        "\t\timage_file = io.BytesIO(image_content)\n",
        "\t\timage = Image.open(image_file)\n",
        "\t\tfile_path = download_path + file_name\n",
        "\n",
        "\t\twith open(file_path, \"wb\") as f:\n",
        "\t\t\timage.save(f, \"JPEG\")\n",
        "\n",
        "\t\tprint(\"Success\")\n",
        "\texcept Exception as e:\n",
        "\t\tprint('FAILED -', e)\n",
        "\n",
        "urls = get_images_from_google(wd, 1, 6)\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "\t\n",
        "  download_image(\"images/\", url, str(i) + \".jpg\")\n",
        "\n",
        "wd.quit()\n",
        "\n",
        "  - Zillow don't let me access the image, gave error message \" please verify you are human, press and hold\" \n",
        "\n",
        "  hold but nothing happening. \n"
      ],
      "metadata": {
        "id": "WTJ-M7a2zlZl"
      }
    }
  ]
}